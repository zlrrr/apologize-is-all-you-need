# LLM Provider Configuration
# Options: lm-studio, openai, anthropic, custom
LLM_PROVIDER=lm-studio

# LM Studio Configuration (for local LLM)
LM_STUDIO_URL=http://127.0.0.1:1234

# OpenAI Configuration (uncomment to use OpenAI)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration (uncomment to use Claude)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# Custom LLM API Configuration (for other OpenAI-compatible APIs)
# CUSTOM_API_KEY=your-custom-api-key-here
# CUSTOM_BASE_URL=https://your-custom-api.com/v1
# CUSTOM_MODEL=your-model-name

# Backend Server Configuration
BACKEND_PORT=5001
BACKEND_HOST=localhost

# Frontend Configuration
VITE_API_URL=http://localhost:5001

# LLM Model Settings (global defaults)
LLM_MODEL_NAME=local-model
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# Session Configuration
SESSION_SECRET=change-this-to-a-random-secret-in-production
